// import { ChatAnthropic } from "@langchain/anthropic";
import { DynamicTool } from "@langchain/core/tools";
import { ToolNode } from "@langchain/langgraph/prebuilt";
import {
  END,
  MemorySaver,
  MessagesAnnotation,
  START,
  StateGraph,
} from "@langchain/langgraph";

import SYSTEM_MESSAGE from "@/constants/system.Message";
import {
  AIMessage,
  BaseMessage,
  HumanMessage,
  SystemMessage,
  trimMessages,
} from "@langchain/core/messages";
import {
  ChatPromptTemplate,
  MessagesPlaceholder,
} from "@langchain/core/prompts";

import { Pinecone } from "@pinecone-database/pinecone";
import { PineconeMatch } from "@/component/model/interface/PineconeMatch";
import { FormattedResult } from "@/component/model/interface/FormattedResult";
import embeddings from "./open-ai";
import { ChatOpenAI } from "@langchain/openai";
import { metadataToString } from "@/functions/metadataToString";
import { extractNumberPrefix } from "@/functions/extractNumberPrefix";

// Define allowed categories as const assertion for better type inference
const ALLOWED_CATEGORIES = [
  "Missing Lessons Series",
  "Checklist Series",
  "Detailed Knowledge Series",
  "Financial Fluency Series",
  "Advisory Essentials Series",
] as const;

// Create a type from the allowed categories
type AllowedCategory = (typeof ALLOWED_CATEGORIES)[number];

// Use faster models strategically
const FAST_MODEL = "gpt-4o-mini"; // Fastest for simple queries
// use this for claude faster = claude-haiku-3-5-20241022
// const BALANCED_MODEL = "claude-sonnet-4-20250514"; // Good balance uncomment this if we will use this
const QUALITY_MODEL = "gpt-4o"; // Best quality
// use this for claude quality = claude-opus-4-20250514

async function querySimilarDocuments(
  queryText: string,
  isDocumentNumberSelected: boolean,
  // topK = 25,
  excludeIds: string[] = []
): Promise<FormattedResult[]> {
  try {
    const pinecone = new Pinecone({
      apiKey: process.env.PINECONE_API_KEY!,
    });

    const index = pinecone.Index(process.env.PINECONE_INDEX_NAME!);

    // Check if queryText contains a 5-digit number
    const fourDigitMatch = queryText.match(/(?:^|\s)(\d{1,5})(?=\s|$)/);

    let finalResults: PineconeMatch[] = [];

    // Helper function to calculate relevance percentage
    const calculateRelevancePercentage = (score: number): number => {
      // Pinecone cosine similarity scores typically range from -1 to 1
      // Convert to percentage (0-100%)
      return Math.round(((score + 1) / 2) * 100);
    };

    if (isDocumentNumberSelected) {
      if (!fourDigitMatch) {
        return [];
      }

      const specificNumber = fourDigitMatch[1];

      // Search specifically for the Missing Lessons document with this number
      const queryResponse = await index.query({
        topK: 500,
        vector: await embeddings.embedQuery(queryText),
        includeMetadata: true,
        includeValues: false,
        filter: {
          documentNumber: {
            $eq: fourDigitMatch[1],
          },
        },
      });

      // Sort matches based on category priority defined in ALLOWED_CATEGORIES
      const sortedMatches = queryResponse.matches.sort((a, b) => {
        const categoryA = metadataToString(a.metadata?.category);
        const categoryB = metadataToString(b.metadata?.category);
        const indexA = ALLOWED_CATEGORIES.indexOf(categoryA as AllowedCategory);
        const indexB = ALLOWED_CATEGORIES.indexOf(categoryB as AllowedCategory);

        // Unknown categories go to the end
        return (indexA === -1 ? 999 : indexA) - (indexB === -1 ? 999 : indexB);
      });

      // Filter for documents that match the specific 3-digit number and meet relevance threshold
      finalResults = sortedMatches.filter((match) => {
        const matchId = metadataToString(match.metadata?.id);
        const documentNumber = metadataToString(match.metadata?.documentNumber);
        const score = match.score ?? 0;
        const scoreRelevant = calculateRelevancePercentage(score);

        // Skip matches with less than 70% relevance
        if (scoreRelevant < 50) {
          console.log(
            `Skipping match with ${scoreRelevant}% relevance (below 70% threshold)`
          );
          return false;
        }

        // Skip if this ID or documentNumber was already shown
        if (
          excludeIds.includes(matchId) ||
          excludeIds.includes(documentNumber)
        ) {
          return false;
        }

        const numberPrefix = extractNumberPrefix(documentNumber);
        return numberPrefix === specificNumber;
      });

      // console.log("finalResults.", finalResults);
    } else {
      const queryEmbedding = await embeddings.embedQuery(queryText);

      // Get more results to account for exclusions and ensure we have enough for all categories
      const initialQueryResponse = await index.query({
        topK: 500, // Get more results to ensure we have enough for all categories
        vector: queryEmbedding,
        includeMetadata: true,
        includeValues: false,
        filter: {
          category: {
            $eq: "Advisory Essentials Series",
          },
        },
      });

      // Separate results by category
      // const categorizedResults: Record<AllowedCategory, PineconeMatch[]> = {
      //   "Missing Lessons Series": [],
      //   "Checklist Series": [],
      //   "Detailed Knowledge Series": [],
      //   "Financial Fluency Series": [],
      //   "Advisory Essentials Series": [],
      // };

      // Step 1: Get exactly 5 documents from Advisory Essentials Series with score > 50
      const selectedAdvisoryDocuments: PineconeMatch[] = [];
      const selectedDocumentNumbers: string[] = [];

      // Filter and get exactly 5 documents from Advisory Essentials Series
      for (const match of initialQueryResponse.matches) {
        if (selectedAdvisoryDocuments.length >= 5) {
          break;
        }

        const score = match.score ?? 0;
        const scoreRelevant = calculateRelevancePercentage(score);
        const matchId = metadataToString(match.metadata?.id);
        const documentNumber = metadataToString(match.metadata?.documentNumber);

        // Only include documents with score > 70 and not in excludeIds
        if (
          scoreRelevant > 60 &&
          documentNumber &&
          !excludeIds.includes(matchId) &&
          !excludeIds.includes(documentNumber)
        ) {
          selectedAdvisoryDocuments.push(match);
          selectedDocumentNumbers.push(documentNumber);
        }
      }

      console.log(
        `Selected ${selectedAdvisoryDocuments.length} Advisory Essentials documents`
      );
      console.log(`Selected document numbers:`, selectedDocumentNumbers);

      // Add the selected Advisory Essentials documents to final results
      finalResults.push(...selectedAdvisoryDocuments);

      // Step 2: Search for documents in other categories using the selected document numbers
      if (selectedDocumentNumbers.length > 0) {
        const otherCategories = [
          "Missing Lessons Series",
          "Checklist Series",
          "Detailed Knowledge Series",
          "Financial Fluency Series",
        ];

        for (const category of otherCategories) {
          const categoryQuery = await index.query({
            topK: 400,
            vector: queryEmbedding,
            includeMetadata: true,
            includeValues: false,
            filter: {
              documentNumber: {
                $in: selectedDocumentNumbers,
              },
            },
          });

          // Filter out excluded IDs and add to final results
          const categoryMatches = categoryQuery.matches.filter((match) => {
            const matchId = metadataToString(match.metadata?.id);
            const documentNumber = metadataToString(
              match.metadata?.documentNumber
            );

            return (
              !excludeIds.includes(matchId) &&
              !excludeIds.includes(documentNumber)
            );
          });

          finalResults.push(...categoryMatches);
          console.log(
            `âœ“ Found ${categoryMatches.length} documents in ${category}`
          );
        }
      }
    }

    // Sort finalResults by category priority before mapping to FormattedResult
    finalResults.sort((a, b) => {
      const categoryA = metadataToString(a.metadata?.category);
      const categoryB = metadataToString(b.metadata?.category);
      const indexA = ALLOWED_CATEGORIES.indexOf(categoryA as AllowedCategory);
      const indexB = ALLOWED_CATEGORIES.indexOf(categoryB as AllowedCategory);

      // Unknown categories go to the end
      const priorityA = indexA === -1 ? 999 : indexA;
      const priorityB = indexB === -1 ? 999 : indexB;

      // Primary sort: by category priority
      if (priorityA !== priorityB) {
        return priorityA - priorityB;
      }

      // Secondary sort: by relevance score (highest first) within same category
      const scoreA = a.score ?? 0;
      const scoreB = b.score ?? 0;
      return scoreB - scoreA;
    });

    // Map to your desired format
    return finalResults.map((match) => {
      const id = match.metadata?.id || "";
      const key = match.metadata?.key;
      const description = match.metadata?.description;
      const documentNumber = match.metadata?.documentNumber;
      const mostUsefulFor = match.metadata?.mostHelpfulFor;

      return {
        key: key,
        id: id,
        documentNumber: documentNumber,
        description: description,
        category: match.metadata?.category,
        mostUsefulFor: mostUsefulFor,
      };
    });
  } catch (error) {
    console.error("Error querying Pinecone:", error);
    return [];
  }
}

// Trim the messages to manage conversation history
const trimmer = trimMessages({
  maxTokens: 2000,
  strategy: "last",
  tokenCounter: (msg) => msg.length,
  includeSystem: true,
  allowPartial: false,
  startOn: "human",
});

// Define your tools to use pdfLists only
const createTools = (isDocumentNumberSelected: boolean) => [
  new DynamicTool({
    name: "quickSearch",
    description:
      "Search for the most relevant documents based on user query. Use only when specific document lookup is needed.",
    func: async (input: string) => {
      const matches = await querySimilarDocuments(
        input,
        isDocumentNumberSelected
      );

      console.log("isDocumentNumberSelected", isDocumentNumberSelected);
      // console.log("matches", matches);
      if (matches.length === 0) {
        return JSON.stringify({
          message: "No relevant documents found for this query.",
          documents: [],
          searchQuery: input,
        });
      }

      console.log("matches", matches);
      const result = {
        searchQuery: input,
        totalResults: matches.length,

        allDocuments: matches.map((doc) => ({
          // title: doc.title,
          id: doc.id, // Use this instead of URL
          key: doc.key,
          description: doc.description,
          category: doc.category,
          documentNumber: doc.documentNumber,
          mostUsefulFor: doc.mostUsefulFor,
          // url: doc.url,
        })),
      };

      return JSON.stringify(result);
    },
  }),
];

// Modified submitQuestion function with required pdfLists
export async function submitQuestion(
  messages: BaseMessage[],
  chatId: string,
  isDocumentNumberSelected: boolean
) {
  // Add caching headers to messages
  const cachedMessages = addCachingHeaders(messages);

  // Create workflow with the pdfLists
  const workflow = createWorkflow(isDocumentNumberSelected);

  // Create a checkpoint to save the state of the conversation
  const checkpointer = new MemorySaver();
  const app = workflow.compile({ checkpointer });

  // Run the graph and stream
  const stream = await app.streamEvents(
    {
      messages: cachedMessages,
    },
    {
      version: "v2",
      configurable: {
        thread_id: chatId,
      },
      streamMode: "messages",
      runId: chatId,
    }
  );

  return stream;
}

// Create workflow with the pdfLists
const createWorkflow = (isDocumentNumberSelected: boolean) => {
  // Create tools with pdfLists
  const tools = createTools(isDocumentNumberSelected);
  const toolNodes = new ToolNode(tools);
  const model = initialiseModel(tools);

  const stateGraph = new StateGraph(MessagesAnnotation)
    .addNode("agent", async (state) => {
      // create the system message content
      const systemContent = SYSTEM_MESSAGE;

      // Create the prompt template with system message and messages placeholder
      const promptTemplate = ChatPromptTemplate.fromMessages([
        new SystemMessage(
          systemContent +
            `
            === SEARCH RESULT DISPLAY RULES ===
            - When user asks for "another result", "another example", "more results", or similar:
              1. Use quickSearch with slightly different search terms if needed
              2. The system will automatically exclude previously shown results
              3. Focus on different aspects of their query
            - Always try to provide different results than previously shown
            - If no new results available, inform the user that all relevant documents have been shown
          `,
          {
            cache_control: { type: "ephemeral" }, // set a cache breakpoint (max number of breakpoints is 4)
          }
        ),
        new MessagesPlaceholder("messages"),
      ]);

      // Trim the messages to manage conversation history
      const trimmedMessages = await trimmer.invoke(state.messages);

      // Format the prompt with the current messages
      const prompt = await promptTemplate.invoke({ messages: trimmedMessages });

      // Get response from the model
      const response = await model.invoke(prompt);

      return { messages: [response] };
    })
    .addNode("tools", toolNodes)
    .addEdge(START, "agent")
    .addConditionalEdges("agent", shouldContinue)
    .addEdge("tools", "agent");

  return stateGraph;
};

// Initialize model with tools
const initialiseModel = (tools: DynamicTool[], useQualityModel = true) => {
  const model = new ChatOpenAI({
    model: useQualityModel ? QUALITY_MODEL : FAST_MODEL, // Fixed logic
    apiKey: process.env.OPENAI_API_KEY,
    temperature: 0.1,
    maxTokens: 4000,
    streaming: true,
  }).bindTools(tools);

  return model;
};

// Determine the next step in the workflow
function shouldContinue(state: typeof MessagesAnnotation.State) {
  const messages = state.messages;
  const latestMessage = messages[messages.length - 1] as AIMessage;

  // If the LLM makes a tool call, then we route to the "tools" node
  if (latestMessage.tool_calls?.length) {
    return "tools";
  }

  // If the last message is a tool message, route back to agent
  if (latestMessage.content && latestMessage._getType() === "tool") {
    return "agent";
  }

  // Otherwise, we stop (reply to the user)
  return END;
}

// Add caching headers to messages
function addCachingHeaders(messages: BaseMessage[]): BaseMessage[] {
  if (!messages.length) return messages;
  const cachedMessages = [...messages];

  // Helper to add cache control
  const addCache = (message: BaseMessage) => {
    const content = message.content;
    if (typeof content === "string") {
      message.content = [
        {
          type: "text",
          text: content,
          cache_control: { type: "ephemeral" },
        },
      ];
    }
  };

  // Cache the last message
  addCache(cachedMessages.at(-1)!);

  // Find and cache the second-to-last human message
  let humanCount = 0;
  for (let i = cachedMessages.length - 1; i >= 0; i--) {
    if (cachedMessages[i] instanceof HumanMessage) {
      humanCount++;
      if (humanCount === 2) {
        addCache(cachedMessages[i]);
        break;
      }
    }
  }

  return cachedMessages;
}
